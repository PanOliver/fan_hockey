{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the teams in the league, we need to get the results in a format we can use.\n",
    "\n",
    "The results are hosted on Yahoo's fantasy hockey site. To date, I've manually retrieved the results and created a csv file (I'll automate it someday). Each week's results are in a separate file in the same directory.\n",
    "\n",
    "I need to retreive results from csv files and put them into a data structure that is easy to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare this workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 12 teams in the league. Their full and abbreviated names will come in handy when diplaying results, so let's code them in.\n",
    "\n",
    "The category names are also coded in (Goals, Assists, Plus/Minus, Hits, Blocked Shots, Goalie Wins, Goalie Save Percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['Basement Dwellers','Chotchmahoneless','Dice-n-Draft','Dont Toews Me Bro','Happys Hustlers','Hard Off the Glass','Neals Neat Team','Newfie Rockers','RyansNOTsoRandomTeam','The Gallows Pole', 'TopShelf','Tylers Tilers']\n",
    "shortnames = ['BDwell','Chotch','D-n-D','Toews','Hustle','HrdGls','NNeatT','Newfie','RnsRT','T G P','TpShlf','Tilers']\n",
    "\n",
    "cats = ['G', 'A', '+/-', 'Hits', 'Blk', 'W', \"SV%\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to load the first week's results into a Numpy array.\n",
    "\n",
    "I've uploaded the league results for weeks 1 through 19 to a Github repository, so we'll grab it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  17.      32.       4.      40.      41.       4.       0.922]\n",
      " [  12.      18.     -14.      57.      42.       5.       0.908]\n",
      " [   6.      22.      -7.      71.      42.       5.       0.893]\n",
      " [   9.       9.       4.     113.      54.       4.       0.906]\n",
      " [  13.      25.       1.      65.      47.       1.       0.897]\n",
      " [   7.      16.      -9.      84.      56.       2.       0.916]\n",
      " [  11.      27.      -2.      54.      65.       3.       0.891]\n",
      " [  11.      35.      16.      95.      58.       6.       0.907]\n",
      " [  14.      33.      -1.      30.      39.       5.       0.898]\n",
      " [  10.      20.      14.      46.      38.       4.       0.897]\n",
      " [   9.      17.      -2.     101.      51.       2.       0.906]]\n"
     ]
    }
   ],
   "source": [
    "# define a function to load a file from Github\n",
    "def loadweekonline(weeknumber):\n",
    "    \n",
    "    url = 'https://raw.githubusercontent.com/scibbatical/fan_hockey/master/w%s.csv' % weeknumber\n",
    "    results = np.array(pd.read_csv(url))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# load a file\n",
    "w1 = loadweekonline(1)\n",
    "        \n",
    "# show results\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great. A week's results are a 2D array. Each row is a team's stats for week 1, and each column is a stat category.\n",
    "\n",
    "We can add another dimension to the data: time. Each week will be represented by a layer, and each layer will be a 2D array of results.\n",
    "\n",
    "Let's define a function to create our 3D result array, then use it to load 19 weeks of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compresultsonline(uptoweek):\n",
    "    \n",
    "    #start by loading the first week    \n",
    "    results = [loadweekonline(1)]\n",
    "    \n",
    "    # now append the other weeks onto results        \n",
    "    for i in range(uptoweek-1):\n",
    "        results = np.append(results,[loadweekonline(i+2)],axis=0)\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "BHLresults = compresultsonline(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now in a 3D array from which we can grab data according to team, week, and category index by:\n",
    "\n",
    "BHLresults[(week),(team),(category)]\n",
    "\n",
    "For example, The Gallows Pole's (team index 9) performance in Goals (category index 0) this season can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.    4.    7.    7.    4.    5.    7.   10.    8.    6.    5.   12.\n",
      "   8.    6.    9.5   8.    6.    7.    7. ]\n"
     ]
    }
   ],
   "source": [
    "print(BHLresults[:,9,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
